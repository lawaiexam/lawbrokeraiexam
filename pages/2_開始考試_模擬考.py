import time
import pandas as pd
import streamlit as st

from services.state_service import ensure_state
from services.auth_service import require_login_or_render
from services.bank_service import load_bank_df
from services.exam_service import build_paper, grade_paper, persist_exam_record
from services.exam_rules import CERT_CATALOG  # âœ… ç”¨ section name å°æ‡‰é¡Œåº«è·¯å¾‘
from components.auth_ui import render_user_panel
from components.sidebar_exam_settings import render_exam_settings
from components.question_render import render_question

ensure_state()

# ========= Sidebar =========
with st.sidebar:
    render_user_panel()

user = require_login_or_render()
if user is None:
    st.stop()

st.title("é–‹å§‹è€ƒè©¦ - æ¨¡æ“¬è€ƒ")

with st.sidebar:
    # âœ… æ¨¡æ“¬è€ƒèµ° mock æ¨¡å¼ï¼ˆè­‰ç…§/ç§‘ç›®æ˜ å°„ + è¦å‰‡é–å®šï¼‰
    settings = render_exam_settings(mode="mock")

spec = settings.get("mock_spec") or {}
sections = spec.get("sections") or []
if not sections:
    st.error("æ­¤è­‰ç…§é¡åˆ¥æ²’æœ‰è¨­å®šæ¨¡æ“¬è€ƒè¦å‰‡ï¼ˆMOCK_SPECSï¼‰ã€‚")
    st.stop()

# ========= åˆå§‹åŒ–ã€Œå…©ç¯€é€£è€ƒã€state =========
if "mock_section_idx" not in st.session_state:
    st.session_state.mock_section_idx = 0

if "mock_section_results" not in st.session_state:
    st.session_state.mock_section_results = []

# ç”¨æ–¼æ•´å ´æ¨¡æ“¬è€ƒçš„èµ·å§‹æ™‚é–“ï¼ˆç¸½è€—æ™‚ï¼‰
if "mock_exam_start_ts" not in st.session_state:
    st.session_state.mock_exam_start_ts = None

# ========= å–å¾—ç›®å‰ç¯€æ¬¡ =========
sec_idx = int(st.session_state.mock_section_idx)
if sec_idx >= len(sections):
    # ä¿éšªï¼šè¶…ç•Œå°±é‡ç½®
    st.session_state.mock_section_idx = 0
    st.session_state.mock_section_results = []
    st.session_state.mock_exam_start_ts = None
    sec_idx = 0

section = sections[sec_idx]
section_name = section.get("name", f"Section{sec_idx+1}")
n_questions = int(section.get("n_questions", 0))
time_limit_sec = int(section.get("time_min", 0) * 60)

if n_questions <= 0 or time_limit_sec <= 0:
    st.error("æ¨¡æ“¬è€ƒè¦å‰‡è¨­å®šä¸å®Œæ•´ï¼ˆé¡Œæ•¸æˆ–æ™‚é–“ç‚º 0ï¼‰ï¼Œè«‹æª¢æŸ¥ MOCK_SPECSã€‚")
    st.stop()

# ========= è¼‰å…¥æœ¬ç¯€é¡Œåº«ï¼ˆä¾ section name å°æ‡‰å›ºå®š Excelï¼‰ =========
try:
    bank_path = CERT_CATALOG[settings["cert_type"]]["subjects"][section_name]
except Exception:
    st.error(f"æ‰¾ä¸åˆ°é¡Œåº«æ˜ å°„ï¼š{settings['cert_type']} â†’ {section_name}ã€‚è«‹æª¢æŸ¥ CERT_CATALOG çš„ subjects key æ˜¯å¦ä¸€è‡´ã€‚")
    st.stop()

# ğŸ› ï¸ ä¿®æ­£é»ï¼šå°‡ bank_source æ”¹ç‚º bank_source_path
df = load_bank_df(
    settings.get("cert_type", ""),  
    merge_all=False,
    bank_source_path=bank_path  # âœ… æ”¹æˆæ­£ç¢ºçš„åƒæ•¸åç¨±
)

if df is None or df.empty:
    st.warning("å°šæœªè¼‰å…¥é¡Œåº«ï¼Œè«‹ç¢ºèªé¡Œåº«æª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”å¯è®€å–ã€‚")
    st.stop()

st.session_state.df = df

# âœ… æ¨¡æ“¬è€ƒä¸é¸ç« ç¯€ï¼šç›´æ¥å…¨é¸
filtered = df

# âœ… æ­·å²ç´€éŒ„ç”¨åç¨±ï¼šçµ±ä¸€ç‚ºã€Œè­‰ç…§ï½œæ¨¡æ“¬è€ƒã€
exam_label = f"{settings['cert_type']}ï½œæ¨¡æ“¬è€ƒ"
st.session_state.current_bank_name = exam_label

# ========= é¡¯ç¤ºç›®å‰ç¯€æ¬¡èˆ‡ç¸½è¦æ ¼ =========
with st.expander("æœ¬æ¬¡æ¨¡æ“¬è€ƒè¦æ ¼ï¼ˆå›ºå®šï¼‰", expanded=True):
    st.write(f"- é¡åˆ¥ï¼š{settings['cert_type']}")
    st.write(f"- æ¨¡å¼ï¼šå…©ç¯€é€£è€ƒ" if len(sections) > 1 else "- æ¨¡å¼ï¼šå–®ç¯€")
    st.write("")

    for i, s in enumerate(sections, start=1):
        st.write(f"- ç¬¬ {i} ç¯€ï¼š{s['name']}ï½œ{s['n_questions']} é¡Œï½œ{s['time_min']} åˆ†é˜")

    if spec.get("mode") == "single":
        st.write(f"âœ… åŠæ ¼ï¼š{spec.get('pass_score')} åˆ†")
    else:
        st.write(f"âœ… åŠæ ¼ï¼šåˆè¨ˆ {spec.get('pass_total')} åˆ†ï¼Œä¸”å–®ç§‘ä¸ä½æ–¼ {spec.get('pass_min_each')} åˆ†")

st.divider()
st.subheader(f"ç¬¬ {sec_idx+1} ç¯€ï¼š{section_name}")

# ========= æœ¬ç¯€é–‹å§‹/é‡ç½® =========
colA, colB = st.columns([1, 1])

def _reset_whole_mock_exam():
    # æœ¬ç¯€ç‹€æ…‹
    for k in ["paper", "answers", "started", "show_results", "saved_to_db", "start_ts", "time_limit"]:
        if k in st.session_state:
            del st.session_state[k]

    # æ•´å ´ç‹€æ…‹
    st.session_state.mock_section_idx = 0
    st.session_state.mock_section_results = []
    st.session_state.mock_exam_start_ts = None

    # æˆç¸¾é¡¯ç¤ºç”¨ï¼ˆé¿å…èˆŠè³‡æ–™æ®˜ç•™ï¼‰
    for k in ["mock_summary", "score_tuple", "wrong_df", "results_df",
              "section_scores", "total_score", "passed", "fail_reason"]:
        if k in st.session_state:
            del st.session_state[k]

with colA:
    if st.button("é–‹å§‹æœ¬ç¯€", type="primary"):
        st.session_state.paper = build_paper(
            filtered,
            n_questions,
            random_order=True,
            shuffle_options=settings["shuffle_options"]
        )
        st.session_state.answers = {}
        st.session_state.started = True
        st.session_state.show_results = False
        st.session_state.saved_to_db = False

        # æœ¬ç¯€é–‹å§‹æ™‚é–“ï¼ˆç¯€æ¬¡å€’æ•¸ï¼‰
        st.session_state.start_ts = time.time()

        # æ•´å ´é–‹å§‹æ™‚é–“ï¼ˆç¸½è€—æ™‚ï¼‰
        if st.session_state.mock_exam_start_ts is None:
            st.session_state.mock_exam_start_ts = st.session_state.start_ts

        # âœ… æœ¬ç¯€æ™‚é–“é–å®š
        st.session_state.time_limit = time_limit_sec
        st.rerun()

with colB:
    if st.button("é‡ç½®æ•´å ´æ¨¡æ“¬è€ƒ", type="secondary"):
        _reset_whole_mock_exam()
        st.rerun()

paper = st.session_state.get("paper")
if not paper:
    st.info("è«‹å…ˆæŒ‰ã€Œé–‹å§‹æœ¬ç¯€ã€ã€‚")
    st.stop()

# ========= Timerï¼ˆæœ¬ç¯€å€’æ•¸ï¼‰ =========
if st.session_state.get("time_limit") and st.session_state.get("start_ts"):
    elapsed = int(time.time() - st.session_state.start_ts)
    remain = max(0, st.session_state.time_limit - elapsed)
    
    # ğŸŸ¢ ä¿®æ”¹é–‹å§‹ï¼šè¨ˆç®—åˆ†èˆ‡ç§’ï¼Œä¸¦æ ¼å¼åŒ–é¡¯ç¤º
    mins, secs = divmod(remain, 60)
    time_str = f"{mins} åˆ† {secs:02d} ç§’"
    st.metric("æœ¬ç¯€å‰©é¤˜æ™‚é–“", time_str)
    # ğŸŸ¢ ä¿®æ”¹çµæŸ

    if remain == 0 and not st.session_state.get("show_results"):
        st.warning("æœ¬ç¯€æ™‚é–“åˆ°ï¼Œè‡ªå‹•äº¤å·ã€‚")
        st.session_state.show_results = True
        st.rerun()

# ========= ä½œç­”å€ï¼ˆæœªäº¤å·æ‰é¡¯ç¤ºï¼‰ =========
if not st.session_state.get("show_results"):
    st.subheader("ä½œç­”å€")
    for idx, q in enumerate(paper, start=1):
        with st.expander(f"ç¬¬ {idx} é¡Œ", expanded=(idx == 1)):
            picked = render_question(
                q,
                show_image=settings["show_image"],
                answer_key=f"mock_s{sec_idx}_ans_{q['ID']}"
            )
            st.session_state.answers[q["ID"]] = picked

    if st.button("äº¤å·ï¼ˆæœ¬ç¯€ï¼‰", type="primary"):
        st.session_state.show_results = True
        st.rerun()

# ========= äº¤å·å¾Œï¼šæœ¬ç¯€è¨ˆåˆ† â†’ å­˜å…¥ section_results â†’ é€²ä¸‹ä¸€ç¯€æˆ–çµæŸ =========
if not st.session_state.get("show_results"):
    st.stop()

results_df, score_tuple, wrong_df = grade_paper(paper, st.session_state.answers)
correct, total, score = score_tuple

# å­˜æœ¬ç¯€çµæœï¼ˆä¾›æœ€å¾Œåˆä½µã€ä¹Ÿä¾› page5 é¡¯ç¤ºï¼‰
st.session_state.mock_section_results.append({
    "section": section_name,
    "score": int(score),
    "correct": int(correct),
    "total": int(total),
    "results_df": results_df,
    "wrong_df": wrong_df,
})

# ========= è‹¥é‚„æœ‰ä¸‹ä¸€ç¯€ï¼šåˆ‡æ›åˆ°ä¸‹ä¸€ç¯€ =========
st.session_state.mock_section_idx += 1

if st.session_state.mock_section_idx < len(sections):
    st.success(f"å·²å®Œæˆç¬¬ {sec_idx+1} ç¯€ï¼š{section_name}ï¼ˆ{score} åˆ†ï¼‰ã€‚")

    # æ¸…æ‰æœ¬ç¯€ç‹€æ…‹ï¼Œæº–å‚™ä¸‹ä¸€ç¯€
    st.session_state.paper = None
    st.session_state.answers = {}
    st.session_state.started = False
    st.session_state.show_results = False
    st.session_state.saved_to_db = False
    st.session_state.start_ts = None
    st.session_state.time_limit = None

    if st.button("å‰å¾€ä¸‹ä¸€ç¯€", type="primary"):
        st.rerun()
    st.stop()

# ========= æœ€å¾Œä¸€ç¯€å®Œæˆï¼šåˆä½µåˆ¤åˆ† â†’ å¯« DB â†’ è·³çµæœé  =========
section_results = st.session_state.mock_section_results

# âœ… å››æ¬„ï¼šsection_scores / total_score / passed / fail_reason
section_scores = {s["section"]: int(s["score"]) for s in section_results}
total_score = int(sum(s["score"] for s in section_results))
min_each = int(min(s["score"] for s in section_results)) if section_results else 0

passed = True
fail_reason = None

if spec.get("mode") == "single":
    pass_score = int(spec.get("pass_score", 0))
    passed = total_score >= pass_score
    if not passed:
        fail_reason = "åˆ†æ•¸æœªé”åŠæ ¼æ¨™æº–"
else:
    pass_total = int(spec.get("pass_total", 0))
    pass_min_each = int(spec.get("pass_min_each", 0))
    passed = (total_score >= pass_total) and (min_each >= pass_min_each)
    if not passed:
        if total_score < pass_total:
            fail_reason = "ç¸½åˆ†ä¸è¶³"
        elif min_each < pass_min_each:
            fail_reason = "å–®ç§‘æœªé”æœ€ä½æ¨™æº–"

passed_db = 1 if passed else 0

# åˆä½µéŒ¯é¡Œï¼ˆå…©ç¯€ä¸€èµ·ï¼‰
all_wrong_df = pd.concat([s["wrong_df"] for s in section_results], ignore_index=True) if section_results else pd.DataFrame()

# åˆä½µ results_dfï¼ˆä¾› page5 é¡¯ç¤ºå…¨åˆ—è¡¨ï¼‰
all_results_df = pd.concat([s["results_df"] for s in section_results], ignore_index=True) if section_results else pd.DataFrame()

# å­˜çµ¦ page5 é¡¯ç¤ºï¼ˆæ–°ç‰ˆï¼‰
st.session_state.mock_summary = {
    "cert_type": settings["cert_type"],
    "sections": [{"name": s["section"], "score": s["score"], "correct": s["correct"], "total": s["total"]} for s in section_results],
    "section_scores": section_scores,
    "total_score": total_score,
    "passed": passed,
    "fail_reason": fail_reason,
}

# ä¹ŸæŠŠå››æ¬„ç¨ç«‹å­˜ä¸€ä»½ï¼ˆpage5 å–ç”¨æ›´ç›´è¦ºï¼‰
st.session_state.section_scores = section_scores
st.session_state.total_score = total_score
st.session_state.passed = passed_db
st.session_state.fail_reason = fail_reason

# ä¿ç•™èˆŠæ¬„ä½ï¼ˆé¿å…ä½  page5 æˆ–å…¶ä»–é é‚„åœ¨ç”¨ score_tuple/wrong_dfï¼‰
total_correct = int(sum(s["correct"] for s in section_results))
total_q = int(sum(s["total"] for s in section_results))
st.session_state.score_tuple = (total_correct, total_q, total_score)
st.session_state.wrong_df = all_wrong_df
st.session_state.results_df = all_results_df

# ========= å¯« DBï¼ˆåªå¯«ä¸€æ¬¡ï¼šæ•´å ´æ¨¡æ“¬è€ƒï¼‰ =========
if not st.session_state.get("saved_to_db") and st.session_state.get("mock_exam_start_ts"):
    duration_sec = int(time.time() - st.session_state.mock_exam_start_ts)
    try:
        persist_exam_record(
            user,
            exam_label,
            (total_correct, total_q, total_score),
            duration_sec,
            all_wrong_df,
            section_scores=section_scores,
            total_score=total_score,
            passed=passed_db,
            fail_reason=fail_reason
        )
        st.session_state.saved_to_db = True
    except Exception as e:
        st.error(f"å¯«å…¥æˆç¸¾å¤±æ•—ï¼š{e}")
        st.stop()

# ========= æ¸…ç†æµç¨‹ç‹€æ…‹ï¼ˆé¿å…å›ä¸Šä¸€é å†é€²ä¾†äº‚æ‰ï¼‰ =========
# ä¿ç•™ï¼šmock_summary/score_tuple/results_df/wrong_df/å››æ¬„ ä¾› page5 ä½¿ç”¨
st.session_state.paper = None
st.session_state.answers = {}
st.session_state.started = False
st.session_state.show_results = False
st.session_state.start_ts = None
st.session_state.time_limit = None

# âœ… è·³åˆ°çµæœé ï¼ˆè«‹ç¢ºä¿æª”åä¸€è‡´ï¼‰
st.switch_page("pages/5_æ¨¡æ“¬è€ƒ_æˆç¸¾èˆ‡éŒ¯é¡Œè§£æ.py")
